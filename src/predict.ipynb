{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "import os\n",
    "from utils import logger\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from utils import logger\n",
    "\n",
    "def lassoSelection(X_train, y_train, n):\n",
    "\t\"\"\"\n",
    "\tLasso feature selection.  Select n features.\n",
    "\t\"\"\"\n",
    "\t#lasso feature selection\n",
    "\t#print (X_train)\n",
    "\tclf = LassoCV()\n",
    "\tsfm = SelectFromModel(clf, threshold=0)\n",
    "\tsfm.fit(X_train, y_train)\n",
    "\tX_transform = sfm.transform(X_train)\n",
    "\tn_features = X_transform.shape[1]\n",
    "\n",
    "\t#print(n_features)\n",
    "\twhile n_features > n:\n",
    "\t\tsfm.threshold += 0.01\n",
    "\t\tX_transform = sfm.transform(X_train)\n",
    "\t\tn_features = X_transform.shape[1]\n",
    "\tfeatures = [index for index,value in enumerate(sfm.get_support()) if value == True  ]\n",
    "\tlogger.info(\"selected features are {}\".format(features))\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def specificity_score(y_true, y_predict):\n",
    "\t'''\n",
    "\ttrue_negative rate\n",
    "\t'''\n",
    "\ttrue_negative = len([index for index,pair in enumerate(zip(y_true,y_predict)) if pair[0]==pair[1] and pair[0]==0 ])\n",
    "\treal_negative = len(y_true) - sum(y_true)\n",
    "\treturn true_negative / real_negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_fit_predict(X_train,X_test,y_train,y_test):\n",
    "    np.random.seed(2018)\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import recall_score\n",
    "\n",
    "    models = {\n",
    "        'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    }\n",
    "    tuned_parameters = {\n",
    "        'KNeighborsClassifier': {'n_neighbors': [3, 5, 7, 10]},\n",
    "    }\n",
    "\n",
    "    scores= {}\n",
    "    for key in models:\n",
    "        clf = GridSearchCV(models[key], tuned_parameters[key], scoring=None,  refit=True, cv=2)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_test_predict = clf.predict(X_test)\n",
    "        precision = precision_score(y_test, y_test_predict, average='micro')\n",
    "        accuracy = accuracy_score(y_test, y_test_predict)\n",
    "        f1 = f1_score(y_test, y_test_predict, average='micro')\n",
    "        recall = recall_score(y_test, y_test_predict, average='micro')\n",
    "        specificity = specificity_score(y_test, y_test_predict)\n",
    "        scores[key] = [precision,accuracy,f1,recall,specificity]\n",
    "        # reture the best model which K hyper-parameter can get the highest performance\n",
    "        best_model = clf.best_estimator_\n",
    "    return scores, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(scores):\n",
    "\t'''\n",
    "\tdraw scores.\n",
    "\t'''\n",
    "\timport matplotlib.pyplot as plt\n",
    "\tlogger.info(\"scores are {}\".format(scores))\n",
    "\tax = plt.subplot(111)\n",
    "\tprecisions = []\n",
    "\taccuracies =[]\n",
    "\tf1_scores = []\n",
    "\trecalls = []\n",
    "\tcategories = []\n",
    "\tspecificities = []\n",
    "\tN = len(scores)\n",
    "\tind = np.arange(N)  # set the x locations for the groups\n",
    "\twidth = 0.1        # the width of the bars\n",
    "\tfor key in scores:\n",
    "\t\tcategories.append(key)\n",
    "\t\tprecisions.append(scores[key][0])\n",
    "\t\taccuracies.append(scores[key][1])\n",
    "\t\tf1_scores.append(scores[key][2])\n",
    "\t\trecalls.append(scores[key][3])\n",
    "\t\tspecificities.append(scores[key][4])\n",
    "\n",
    "\tprecision_bar = ax.bar(ind, precisions,width=0.1,color='b',align='center')\n",
    "\taccuracy_bar = ax.bar(ind+1*width, accuracies,width=0.1,color='g',align='center')\n",
    "\tf1_bar = ax.bar(ind+2*width, f1_scores,width=0.1,color='r',align='center')\n",
    "\trecall_bar = ax.bar(ind+3*width, recalls,width=0.1,color='y',align='center')\n",
    "\tspecificity_bar = ax.bar(ind+4*width,specificities,width=0.1,color='purple',align='center')\n",
    "\n",
    "\tprint(categories)\n",
    "\tax.set_xticks(np.arange(N))\n",
    "\tax.set_xticklabels(categories)\n",
    "\tax.legend((precision_bar[0], accuracy_bar[0],f1_bar[0],recall_bar[0],specificity_bar[0]), ('precision', 'accuracy','f1','sensitivity','specificity'))\n",
    "\tax.grid()\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir =\"/Users/xin/Downloads/EE542/Labs/lab10/data/\"\n",
    "data_file = data_dir + \"miRNA_matrix.csv\"\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0     1104\n",
      "4.0     1081\n",
      "22.0    1000\n",
      "0.0      691\n",
      "Name: label, dtype: int64\n",
      "(3876, 1883)\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df = df.dropna()\n",
    "n_labels = df['label'].value_counts()\n",
    "print(n_labels)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xin/anaconda/envs/py3k/lib/python3.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "\ty_data = df.pop('label').values\n",
    "\n",
    "\tdf.pop('file_id')\n",
    "\n",
    "\tcolumns =df.columns\n",
    "\t#print (columns)\n",
    "\tX_data = df.values\n",
    "\n",
    "\t# split the data to train and test set\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=0)\n",
    "\n",
    "\t#standardize the data.\n",
    "\tscaler = StandardScaler()\n",
    "\tscaler.fit(X_train)\n",
    "\tX_train = scaler.transform(X_train)\n",
    "\tX_test = scaler.transform(X_test)\n",
    "\t\n",
    "\t# check the distribution of tumor and normal sampels in traing and test data set.\n",
    "\t#logger.info(\"Percentage of tumor cases in training set is {}\".format(sum(y_train)/len(y_train)))\n",
    "\t#logger.info(\"Percentage of tumor cases in test set is {}\".format(sum(y_test)/len(y_test)))\n",
    "\n",
    "#\tn = 7\n",
    "#\tfeaures_columns = lassoSelection(X_train, y_train, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA reduction\n",
      "feature numbers: 800\n",
      "explained_variance_ratio_.cumsum: \n",
      "[0.10758068 0.14623727 0.17507563 0.19643368 0.2134912  0.22936297\n",
      " 0.24199373 0.25173982 0.26126811 0.27001589 0.27850101 0.28660775\n",
      " 0.29410522 0.30154883 0.30849357 0.31524676 0.32192201 0.32840342\n",
      " 0.33444177 0.34032085 0.34595511 0.35137228 0.35632701 0.36101151\n",
      " 0.36524293 0.36936671 0.37334287 0.37706706 0.38072737 0.38417798\n",
      " 0.38754154 0.39079842 0.39400397 0.3971264  0.40023967 0.40331536\n",
      " 0.40628956 0.40915805 0.41201747 0.4148206  0.4175999  0.42031404\n",
      " 0.42299133 0.42558671 0.42809902 0.43058274 0.4330144  0.43541766\n",
      " 0.43777689 0.4401144  0.44241565 0.44468665 0.44691173 0.44912386\n",
      " 0.45131458 0.45349178 0.45562646 0.45773638 0.45983465 0.46192197\n",
      " 0.4639719  0.4660178  0.46806294 0.47007978 0.47208    0.47406286\n",
      " 0.47603513 0.47798539 0.47992012 0.48182803 0.48371474 0.48559473\n",
      " 0.48745974 0.48930764 0.49114008 0.4929531  0.49475525 0.49655599\n",
      " 0.49833986 0.50011127 0.50186729 0.50358998 0.50530669 0.50701576\n",
      " 0.50871538 0.51040386 0.51207575 0.51373884 0.51539053 0.51701796\n",
      " 0.51863447 0.52024957 0.52184948 0.52344168 0.52503159 0.52661127\n",
      " 0.52817284 0.52972813 0.53127488 0.53281263 0.53434005 0.53585975\n",
      " 0.53736944 0.53887115 0.54036479 0.54185025 0.54332832 0.54479605\n",
      " 0.54626039 0.54771389 0.54915537 0.55059211 0.55201605 0.5534304\n",
      " 0.55484435 0.55624665 0.55764359 0.55903514 0.5604107  0.56177611\n",
      " 0.56313421 0.56448605 0.56583273 0.56717422 0.56850795 0.56983272\n",
      " 0.57115441 0.57245979 0.57375715 0.57505085 0.57633951 0.57762327\n",
      " 0.57890231 0.58017276 0.58143717 0.58269699 0.58395534 0.58520918\n",
      " 0.58645593 0.58769101 0.58892062 0.59014495 0.59136757 0.59258363\n",
      " 0.59379182 0.59499797 0.59620057 0.59739958 0.59858986 0.59977831\n",
      " 0.60096117 0.60214039 0.60331463 0.60448287 0.60564697 0.60680798\n",
      " 0.60796525 0.60911173 0.6102573  0.61140065 0.61254189 0.61367409\n",
      " 0.6148057  0.61593311 0.61705819 0.6181801  0.6192925  0.62040249\n",
      " 0.62150668 0.6226075  0.62370683 0.62480135 0.62589026 0.62697236\n",
      " 0.62804782 0.629122   0.6301948  0.63126203 0.63231976 0.63337521\n",
      " 0.63442977 0.63548059 0.63652681 0.63756989 0.63860944 0.63964581\n",
      " 0.64067526 0.64170223 0.6427256  0.64374834 0.6447696  0.64578587\n",
      " 0.64680001 0.64781137 0.64881912 0.64982405 0.65082437 0.65181926\n",
      " 0.65281328 0.65379834 0.65478276 0.65576597 0.65674492 0.65772223\n",
      " 0.65869765 0.65966912 0.66063803 0.66160134 0.66256141 0.66351857\n",
      " 0.66447395 0.6654275  0.66637894 0.66732526 0.66826946 0.66921047\n",
      " 0.67014901 0.67108248 0.67201402 0.67294474 0.67387363 0.67479998\n",
      " 0.67572261 0.67664044 0.6775566  0.67847042 0.67938249 0.68029295\n",
      " 0.68119993 0.68210543 0.68300745 0.68390712 0.68480512 0.68570013\n",
      " 0.68659151 0.68748007 0.6883666  0.68924888 0.69012611 0.69100147\n",
      " 0.69187501 0.69274464 0.69361371 0.69447965 0.6953433  0.69620405\n",
      " 0.69705917 0.69791338 0.69876528 0.69961528 0.70046281 0.70130951\n",
      " 0.70215553 0.70299543 0.70383376 0.70467143 0.70550719 0.70633928\n",
      " 0.70716845 0.70799569 0.70881863 0.70964119 0.71046242 0.71128136\n",
      " 0.71209834 0.71291356 0.71372584 0.71453589 0.71534299 0.71614951\n",
      " 0.71695413 0.71775642 0.71855699 0.7193545  0.72014938 0.72094257\n",
      " 0.72173368 0.72252307 0.72331121 0.72409791 0.72488093 0.72566241\n",
      " 0.72644191 0.72721969 0.72799552 0.72876887 0.72954114 0.73031042\n",
      " 0.73107744 0.7318429  0.73260753 0.73336813 0.73412811 0.73488604\n",
      " 0.73564299 0.73639826 0.73715172 0.73790309 0.7386524  0.73939899\n",
      " 0.74014469 0.74088836 0.74162934 0.74236927 0.74310817 0.74384352\n",
      " 0.74457778 0.74530857 0.74603802 0.74676684 0.74749338 0.74821886\n",
      " 0.74894203 0.74966347 0.75038198 0.7510974  0.75181112 0.75252331\n",
      " 0.75323545 0.75394526 0.75465338 0.75535723 0.75605962 0.75676119\n",
      " 0.75746182 0.75816013 0.75885749 0.75955227 0.76024636 0.76093816\n",
      " 0.76162859 0.7623165  0.76300339 0.76368874 0.76437135 0.76505266\n",
      " 0.76573221 0.76641014 0.76708697 0.76776161 0.76843479 0.7691061\n",
      " 0.76977705 0.77044637 0.77111477 0.77178094 0.77244478 0.77310745\n",
      " 0.77376858 0.77442838 0.77508439 0.77573965 0.77639371 0.77704593\n",
      " 0.77769727 0.77834686 0.77899597 0.77964199 0.78028735 0.78093129\n",
      " 0.78157335 0.78221336 0.78285219 0.78348978 0.78412442 0.78475865\n",
      " 0.78539124 0.78602235 0.78665125 0.78727937 0.7879064  0.78853165\n",
      " 0.78915609 0.7897775  0.79039697 0.79101401 0.79163056 0.79224462\n",
      " 0.79285783 0.79346971 0.79407943 0.79468901 0.79529636 0.795901\n",
      " 0.7965047  0.7971059  0.7977067  0.79830696 0.79890537 0.79950188\n",
      " 0.80009697 0.80069105 0.80128279 0.80187346 0.80246242 0.80305119\n",
      " 0.80363711 0.804222   0.80480491 0.80538698 0.80596837 0.80654861\n",
      " 0.8071272  0.80770392 0.80827964 0.80885381 0.80942664 0.80999787\n",
      " 0.81056746 0.81113623 0.81170395 0.81227054 0.81283585 0.81339971\n",
      " 0.81396215 0.81452361 0.81508326 0.81564058 0.81619664 0.81675122\n",
      " 0.81730424 0.81785603 0.81840482 0.81895251 0.81949957 0.82004462\n",
      " 0.82058842 0.82113132 0.82167288 0.8222132  0.82275215 0.82328918\n",
      " 0.82382474 0.8243594  0.82489166 0.82542273 0.82595246 0.82648138\n",
      " 0.82700774 0.82753284 0.82805693 0.82857958 0.8291013  0.82962286\n",
      " 0.83014107 0.83065845 0.83117423 0.83168973 0.83220369 0.83271685\n",
      " 0.8332287  0.83373934 0.83424896 0.8347572  0.83526355 0.83576857\n",
      " 0.83627291 0.83677483 0.83727529 0.83777409 0.83827212 0.83876843\n",
      " 0.83926264 0.83975567 0.84024822 0.84073989 0.84122995 0.84171891\n",
      " 0.84220669 0.8426937  0.84318018 0.84366536 0.84414936 0.84463227\n",
      " 0.84511396 0.84559283 0.84607108 0.84654686 0.84702009 0.84749162\n",
      " 0.84796201 0.84843206 0.8489006  0.84936735 0.84983313 0.85029829\n",
      " 0.85076249 0.85122574 0.85168848 0.85214936 0.85260857 0.8530673\n",
      " 0.85352548 0.85398214 0.85443793 0.85489297 0.85534714 0.8557988\n",
      " 0.85624946 0.85669908 0.85714742 0.85759463 0.85804022 0.85848463\n",
      " 0.85892838 0.85937019 0.85981101 0.86025042 0.86068965 0.86112761\n",
      " 0.86156488 0.86200049 0.86243526 0.86286948 0.86330278 0.86373419\n",
      " 0.86416424 0.8645933  0.86502069 0.86544717 0.86587283 0.86629719\n",
      " 0.86672048 0.8671427  0.86756415 0.8679847  0.86840277 0.86881876\n",
      " 0.86923411 0.86964819 0.87006194 0.87047385 0.870885   0.8712954\n",
      " 0.8717055  0.87211383 0.87252196 0.87292895 0.87333455 0.87373967\n",
      " 0.87414239 0.87454423 0.87494534 0.87534615 0.87574588 0.87614464\n",
      " 0.87654221 0.87693799 0.87733323 0.87772694 0.87812034 0.87851298\n",
      " 0.87890455 0.87929464 0.87968385 0.88007201 0.88045897 0.88084567\n",
      " 0.88122973 0.88161329 0.88199553 0.88237754 0.88275778 0.88313668\n",
      " 0.88351469 0.88389115 0.88426662 0.88464159 0.8850152  0.88538858\n",
      " 0.88576105 0.88613197 0.88650249 0.88687145 0.88723934 0.88760675\n",
      " 0.88797215 0.88833685 0.88870013 0.88906267 0.88942347 0.88978379\n",
      " 0.89014374 0.89050331 0.8908615  0.89121833 0.89157349 0.89192804\n",
      " 0.89228219 0.89263625 0.8929891  0.89334026 0.89369052 0.89404007\n",
      " 0.8943883  0.89473537 0.89508159 0.89542629 0.89577027 0.89611329\n",
      " 0.89645583 0.89679797 0.89713891 0.89747931 0.89781902 0.89815775\n",
      " 0.89849497 0.89883047 0.89916463 0.89949844 0.89983143 0.9001634\n",
      " 0.90049508 0.90082573 0.90115607 0.90148579 0.90181403 0.90214105\n",
      " 0.90246791 0.90279201 0.90311524 0.90343792 0.90376041 0.90408273\n",
      " 0.90440342 0.90472268 0.9050417  0.90536026 0.90567843 0.90599473\n",
      " 0.90631014 0.90662529 0.90693924 0.90725191 0.90756286 0.90787377\n",
      " 0.9081838  0.90849292 0.90880176 0.90910943 0.90941609 0.9097219\n",
      " 0.91002709 0.91033127 0.91063447 0.91093729 0.91123925 0.91153948\n",
      " 0.91183939 0.91213808 0.91243589 0.91273325 0.91303014 0.91332643\n",
      " 0.91362061 0.91391469 0.91420721 0.91449888 0.91479023 0.91508106\n",
      " 0.91537091 0.91566032 0.91594762 0.91623427 0.9165194  0.91680401\n",
      " 0.91708762 0.91737087 0.91765315 0.9179339  0.91821395 0.91849341\n",
      " 0.91877156 0.91904907 0.91932575 0.91960216 0.91987786 0.9201521\n",
      " 0.92042575 0.92069876 0.92097114 0.9212429  0.92151386 0.92178351\n",
      " 0.92205258 0.92232104 0.92258868 0.92285597 0.92312305 0.92338923\n",
      " 0.92365403 0.92391831 0.92418131 0.92444329 0.92470466 0.92496583\n",
      " 0.92522576 0.925485   0.92574349 0.92600085 0.92625739 0.92651348\n",
      " 0.92676856 0.9270227  0.92727613 0.92752908 0.92778165 0.92803265\n",
      " 0.92828334 0.92853338 0.92878263 0.92903095 0.9292782  0.92952501\n",
      " 0.92977155 0.9300168  0.9302611  0.93050449 0.93074693 0.93098849\n",
      " 0.93122886 0.93146909 0.93170854 0.93194769 0.93218595 0.93242328\n",
      " 0.93265971 0.93289494 0.93312956 0.93336386 0.93359771 0.93383041\n",
      " 0.93406235 0.93429365 0.93452415 0.93475357 0.93498267 0.93521132\n",
      " 0.93543969 0.93566721 0.93589353 0.93611906 0.93634375 0.93656739\n",
      " 0.93679099 0.93701411 0.93723628 0.93745688 0.93767681 0.93789622\n",
      " 0.93811505 0.93833317 0.93855122 0.93876764 0.93898367 0.93919921\n",
      " 0.93941456 0.93962886 0.9398423  0.94005492 0.94026684 0.94047801\n",
      " 0.94068752 0.94089635 0.94110492 0.94131273 0.94152022 0.94172616\n",
      " 0.94193121 0.94213531 0.94233868 0.94254141 0.94274306 0.94294434\n",
      " 0.94314446 0.94334342 0.94354208 0.94373893 0.94393519 0.94413116\n",
      " 0.94432691 0.94452181 0.94471531 0.94490856 0.94510154 0.94529262\n",
      " 0.94548302 0.94567274 0.94586204 0.94605027 0.94623758 0.9464236\n",
      " 0.94660837 0.94679107 0.94697343 0.94715517 0.94733556 0.94751568\n",
      " 0.94769379 0.94787098]\n",
      "t-SNE evaluation\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "num_features=800\n",
    "pca = PCA(n_components=num_features, whiten=True)\n",
    "pca.fit(X_train)\n",
    "X_train = pd.DataFrame(pca.transform(X_train))\n",
    "X_test = pd.DataFrame(pca.transform(X_test))\n",
    "print(\"PCA reduction\")\n",
    "print(\"feature numbers: \"+str(num_features))\n",
    "#print(\"explained_variance_ratio_: \\n\"+str(pca.explained_variance_ratio_))\n",
    "#print(\"explained_variance_ratio_.cumsum: \\n\"+str(pca.explained_variance_ratio_.cumsum())) \n",
    "    \n",
    "#t-SNE better for higher scatter different classes, but only accept number of features is inferior to 4\n",
    "print(\"t-SNE evaluation\")\n",
    "#tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=250)\n",
    "#new = tsne.fit_transform(X_train)\n",
    "#features = pd.DataFrame(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-22 21:55:29,467 - GDC - INFO] scores are {'KNeighborsClassifier': [0.40928632846087704, 0.40928632846087704, 0.4092863284608771, 0.40928632846087704, -0.0048946295037389535]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KNeighborsClassifier']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores, models = model_fit_predict(X_train,X_test,y_train,y_test)\n",
    "draw(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0     1104\n",
      "4.0     1081\n",
      "22.0    1000\n",
      "0.0      691\n",
      "Name: label, dtype: int64\n",
      "691\n",
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(n_labels)\n",
    "print(n_labels[0])\n",
    "print(y_test[y_test[:]==2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = models.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.4 0.5 ... 0.4 0.3 0.2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, array([ 2.,  0.,  4., ..., 22.,  0.,  4.]))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_pred), (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = models.predict_proba(X_test)[:, 1]\n",
    "\n",
    "for i in (2.0,4.0,22.0):\n",
    "    mask = ((y_test[:] == 0) & (y_test[:] == i))\n",
    "    arr_test = y_test[mask]\n",
    "    arr_pred = y_pred[mask]\n",
    "    print(arr_test)\n",
    "    print(arr_pred)\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = roc_curve(arr_test, arr_pred)\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label='KNN')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve - RF model')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fpr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-010ee81baeff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fpr' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.auc(fpr,tpr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
